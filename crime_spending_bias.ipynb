{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime rate and Funding visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "FP_SAFETY_DATA = os.path.join('data','safety_funding.csv')\n",
    "FP_FIG_SPENDING_VS_CRIME_OUT = os.path.join('plots','spending_vs_crime.svg')\n",
    "FP_FIG_SPENDING_OUT = os.path.join('plots','spending.svg')\n",
    "assert os.path.exists(FP_SAFETY_DATA)\n",
    "## NPD list of comparable cities\n",
    "comp = ['Brookline', \n",
    "        'Cambridge',\n",
    "        'Framingham',\n",
    "        'Malden',\n",
    "        'Medford',\n",
    "        'Melrose',\n",
    "        'Quincy',\n",
    "        'Somerville',\n",
    "        'Waltham',\n",
    "        'Watertown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FP_SAFETY_DATA,delimiter='\\t')\n",
    "df['Police Budget per capita'] = df['Police Budget per capita'].str.replace('$','').astype(float)\n",
    "newton = df[df.name=='Newton']\n",
    "df = df.loc[:23].drop(19).infer_objects().sort_index(ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'Total Crime Rate (per 1,000 residents)'\n",
    "y = 'Police Budget per capita'\n",
    "sns.regplot(data=df,\n",
    "            x=x,\n",
    "            y=y)\n",
    "plt.scatter(newton[x],\n",
    "            newton[y],\n",
    "            marker='X',\n",
    "            color='k',\n",
    "            label='Newton')\n",
    "plt.title('Crime and Police Funding in Greater Boston')\n",
    "plt.legend(bbox_to_anchor = [1.35,1.0])\n",
    "plt.savefig(FP_FIG_SPENDING_VS_CRIME_OUT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdspending = 'Police Budget per capita'\n",
    "crime = 'Total Crime Rate (per 1,000 residents)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(newton[pdspending] - df[pdspending].median())*int(newton.Population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=[3.5,5])\n",
    "plt.hlines(df[pdspending].median(),-.1,0.1,label='median')\n",
    "plt.scatter([0],newton[pdspending],marker='d',s=20,label='Newton')\n",
    "sns.scatterplot(x=np.full(len(df),0),y=pdspending,data=df,hue='name',palette='BuGn_d')\n",
    "plt.legend(bbox_to_anchor=[1.8,1])\n",
    "plt.xlim(-0.5,0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FP_FIG_SPENDING_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field Interrogations and Observations\n",
    "2015- May 2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "FP_FIO = 'data/FIO.csv'\n",
    "FP_DEMOGRAPHICS = 'data/newton_demographics.csv'\n",
    "FP_FIG_FIO_COUNT_OUT = 'plots/fio_allstops_proportional_to_race.svg'\n",
    "\n",
    "assert os.path.exists(FP_FIO)\n",
    "assert os.path.exists(FP_DEMOGRAPHICS)\n",
    "\n",
    "#demographic map\n",
    "demo_map = {'W':'White',\n",
    "            'B':'Black or African American',\n",
    "            'A':'Asian',\n",
    "            'I':'American Indian and Alaska Native',\n",
    "            'H':'Hispanic or Latino (of any race)',\n",
    "            'U':'unknown'}\n",
    "map_demo_label = lambda demo_abbrev: demo_map[demo_abbrev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fio = pd.read_csv(FP_FIO)\n",
    "fio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_csv(FP_DEMOGRAPHICS,usecols=['demographic','Newton'])\n",
    "#aggregate demographics not listed in FIOs as \"unknown\"\n",
    "unknown_demos = ['Native Hawaiian and Other Pacific Islander','Some other race','Two or more races']\n",
    "unknown_mask = [demographic in unknown_demos for demographic in demo.demographic]\n",
    "demo.loc[8,:] = ['unknown',demo[unknown_mask].Newton.sum()]\n",
    "demo = demo.set_index('demographic').drop(labels=unknown_demos).reset_index()\n",
    "demo.columns=['demographic','demo_proportion']\n",
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fio_byrace = fio.groupby('Race').count()['Date/Time'].reset_index()\n",
    "fio_byrace['Race'] = fio_byrace.Race.apply(map_demo_label)\n",
    "fio_byrace.columns=['demographic','count']\n",
    "fio_byrace['count_proportion'] = fio_byrace['count']/len(fio)\n",
    "\n",
    "fio_byrace = fio_byrace.set_index('demographic').join(demo.set_index('demographic'))\n",
    "\n",
    "#calculate FIO stops proportionally\n",
    "count_proportionally = lambda x : x[1]/x[2]\n",
    "fio_byrace['stop_liklihood'] = fio_byrace.apply(count_proportionally,raw=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fio_byrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fio_byrace.stop_liklihood.plot(kind='bar')\n",
    "plt.title('Liklihood of having police field interactions\\nproportional to race/ethnicity')\n",
    "plt.savefig(FP_FIG_FIO_COUNT_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_blktowhite = fio_byrace.loc['Black or African American'].stop_liklihood / fio_byrace.loc['White'].stop_liklihood\n",
    "print(f'If you are Black in Newton, you are {np.round(ratio_blktowhite,3)} times more likely to have field interactions with the police than a white person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_lattowhite = fio_byrace.loc['Hispanic or Latino (of any race)'].stop_liklihood / fio_byrace.loc['White'].stop_liklihood\n",
    "print(f'If you are Latinx in Newton, you are {np.round(ratio_lattowhite,3)} times more likely to have field interactions with the police than a white person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about officer initiated??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "FP_TRAFFIC_DATA = 'data/NPD race and traffic stops.csv'\n",
    "FP_FIG_CITATIONS_OUT = 'plots/citation_rate.svg'\n",
    "assert os.path.exists(FP_TRAFFIC_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = pd.read_csv(FP_TRAFFIC_DATA)\n",
    "traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_black = traffic.groupby('Race/ethnicity').get_group('Black')\n",
    "traffic_black.Warnings.sum()/traffic_black.Citations.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_white = traffic.groupby('Race/ethnicity').get_group('White')\n",
    "traffic_white.Warnings.sum()/traffic_white.Citations.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = traffic['Race/ethnicity'].unique()\n",
    "by_race = traffic.groupby('Race/ethnicity')\n",
    "warnings = [by_race.get_group(race).Warnings.sum() for race in races]\n",
    "citations = [by_race.get_group(race).Citations.sum() for race in races]\n",
    "demo_proportion = []\n",
    "for race in races:\n",
    "    demo_mask = [race in demographic for demographic in demo.demographic]\n",
    "    prop = demo.demo_proportion[demo_mask].values\n",
    "    demo_proportion.append(prop[0])\n",
    "traffic_proportionally = pd.DataFrame({'demographic':races,\n",
    "                                       'warnings':warnings,\n",
    "                                       'citations':citations,\n",
    "                                       'demo_prop':demo_proportion})\n",
    "traffic_proportionally['warn_prop'] = traffic_proportionally.warnings/traffic_proportionally.warnings.sum()\n",
    "traffic_proportionally['cit_prop'] = traffic_proportionally.citations/traffic_proportionally.citations.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_proportionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate traffic stop outcomes proportionally\n",
    "\n",
    "citations_proportional_demo = lambda x : x[5]/x[3]\n",
    "traffic_proportionally['citation_rate'] = traffic_proportionally.apply(citations_proportional_demo,raw=True,axis=1)\n",
    "\n",
    "warnings_proportional_demo = lambda x : x[4]/x[3]\n",
    "traffic_proportionally['warning_rate'] = traffic_proportionally.apply(warnings_proportional_demo,raw=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_proportionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_proportionally.set_index('demographic').drop('unknown').citation_rate.plot(kind='bar')\n",
    "plt.savefig(FP_FIG_CITATIONS_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_black = traffic_proportionally.set_index('demographic').loc['Black','citation_rate']/traffic_proportionally.set_index('demographic').loc['White','citation_rate']\n",
    "print(f\"If you're Black and driving in Newton you are {np.round(likelihood_black,3)} times more likely to get a traffic citation than if you're white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('cc': conda)",
   "language": "python",
   "name": "python37364bitcccondab310b95b58a64caabcd495973d06bd5b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
